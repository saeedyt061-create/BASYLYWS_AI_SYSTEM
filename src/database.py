#!/usr/bin/env python3
"""
Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¹Ù„Ù… - Learning Database
=======================================
ØªØ®Ø²Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙˆÙ„ÙŠØ¯Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª ÙˆØ§Ù„ØªØ¹Ù„Ù… Ù…Ù†Ù‡Ø§
"""

import sqlite3
import json
import hashlib
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass


@dataclass
class GenerationRecord:
    """Ø³Ø¬Ù„ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯"""
    id: Optional[int]
    prompt: str
    generated_code: str
    language: str
    quality_score: float
    user_feedback: Optional[str]
    created_at: datetime


class LearningDatabase:
    """
    Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªÙˆÙ„ÙŠØ¯Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    """
    
    def __init__(self, db_path: str = "data/saeed_ai.db"):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        
        Args:
            db_path: Ù…Ø³Ø§Ø± Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.conn = sqlite3.connect(str(self.db_path))
        self.conn.row_factory = sqlite3.Row
        
        self._init_tables()
        print(f"âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {db_path}")
    
    def _init_tables(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„"""
        cursor = self.conn.cursor()
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯Ø§Øª
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS generations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                prompt TEXT NOT NULL,
                prompt_hash TEXT UNIQUE,
                generated_code TEXT NOT NULL,
                language TEXT DEFAULT 'python',
                code_type TEXT DEFAULT 'function',
                quality_score REAL,
                execution_time_ms REAL,
                user_rating INTEGER,
                user_feedback TEXT,
                metadata TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analyses (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                code_hash TEXT UNIQUE,
                code_snippet TEXT,
                language TEXT,
                metrics TEXT,
                issues TEXT,
                code_smells TEXT,
                quality_score REAL,
                analyzed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø«ØºØ±Ø§Øª
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS vulnerabilities (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                code_hash TEXT,
                vulnerability_type TEXT,
                severity TEXT,
                description TEXT,
                fix_suggestion TEXT,
                detected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø£Ù…Ù†ÙŠ
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS security_scans (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                target TEXT,
                scope_file TEXT,
                findings_count INTEGER,
                risk_score INTEGER,
                report_path TEXT,
                scanned_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                stat_type TEXT,
                stat_value REAL,
                stat_date DATE DEFAULT CURRENT_DATE
            )
        ''')
        
        # ÙÙ‡Ø§Ø±Ø³
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_gen_prompt ON generations(prompt_hash)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_gen_date ON generations(created_at)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_analyses_hash ON analyses(code_hash)')
        
        self.conn.commit()
    
    # ========== Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯ ==========
    
    def save_generation(self, 
                        prompt: str,
                        generated_code: str,
                        language: str = "python",
                        code_type: str = "function",
                        quality_score: float = 0.0,
                        execution_time_ms: float = 0.0,
                        metadata: Dict = None) -> int:
        """
        Ø­ÙØ¸ ØªÙˆÙ„ÙŠØ¯ Ø¬Ø¯ÙŠØ¯
        
        Args:
            prompt: Ø§Ù„ÙˆØµÙ/Ø§Ù„Ø·Ù„Ø¨
            generated_code: Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙˆÙ„Ø¯
            language: Ù„ØºØ© Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©
            code_type: Ù†ÙˆØ¹ Ø§Ù„ÙƒÙˆØ¯
            quality_score: Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬ÙˆØ¯Ø©
            execution_time_ms: ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°
            metadata: Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            
        Returns:
            Ù…Ø¹Ø±Ù Ø§Ù„Ø³Ø¬Ù„
        """
        prompt_hash = hashlib.md5(prompt.encode()).hexdigest()
        
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT OR REPLACE INTO generations 
            (prompt, prompt_hash, generated_code, language, code_type, 
             quality_score, execution_time_ms, metadata)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            prompt, prompt_hash, generated_code, language, code_type,
            quality_score, execution_time_ms, json.dumps(metadata or {})
        ))
        
        self.conn.commit()
        return cursor.lastrowid
    
    def get_generation(self, prompt: str) -> Optional[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙˆÙ„ÙŠØ¯ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„ÙˆØµÙ"""
        prompt_hash = hashlib.md5(prompt.encode()).hexdigest()
        
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT * FROM generations WHERE prompt_hash = ?
        ''', (prompt_hash,))
        
        row = cursor.fetchone()
        if row:
            return dict(row)
        return None
    
    def get_similar_generations(self, prompt: str, limit: int = 5) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙˆÙ„ÙŠØ¯Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø©"""
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT * FROM generations 
            WHERE prompt LIKE ?
            ORDER BY quality_score DESC, created_at DESC
            LIMIT ?
        ''', (f'%{prompt[:50]}%', limit))
        
        return [dict(row) for row in cursor.fetchall()]
    
    def update_user_feedback(self, generation_id: int, 
                             rating: int, 
                             feedback: str):
        """ØªØ­Ø¯ÙŠØ« ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        cursor = self.conn.cursor()
        cursor.execute('''
            UPDATE generations 
            SET user_rating = ?, user_feedback = ?
            WHERE id = ?
        ''', (rating, feedback, generation_id))
        self.conn.commit()
    
    # ========== Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ ==========
    
    def save_analysis(self,
                      code: str,
                      language: str,
                      metrics: Dict,
                      issues: List,
                      code_smells: List,
                      quality_score: float) -> int:
        """Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ ÙƒÙˆØ¯"""
        code_hash = hashlib.md5(code.encode()).hexdigest()
        
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT OR REPLACE INTO analyses
            (code_hash, code_snippet, language, metrics, issues, code_smells, quality_score)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (
            code_hash,
            code[:1000],  # ØªØ®Ø²ÙŠÙ† Ø¬Ø²Ø¡ ÙÙ‚Ø·
            language,
            json.dumps(metrics),
            json.dumps(issues),
            json.dumps(code_smells),
            quality_score
        ))
        
        self.conn.commit()
        return cursor.lastrowid
    
    def get_analysis(self, code: str) -> Optional[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø³Ø§Ø¨Ù‚"""
        code_hash = hashlib.md5(code.encode()).hexdigest()
        
        cursor = self.conn.cursor()
        cursor.execute('SELECT * FROM analyses WHERE code_hash = ?', (code_hash,))
        
        row = cursor.fetchone()
        if row:
            result = dict(row)
            result['metrics'] = json.loads(result['metrics'])
            result['issues'] = json.loads(result['issues'])
            result['code_smells'] = json.loads(result['code_smells'])
            return result
        return None
    
    # ========== Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø«ØºØ±Ø§Øª ==========
    
    def save_vulnerability(self,
                           code: str,
                           vuln_type: str,
                           severity: str,
                           description: str,
                           fix_suggestion: str):
        """Ø­ÙØ¸ Ø«ØºØ±Ø© Ù…ÙƒØªØ´ÙØ©"""
        code_hash = hashlib.md5(code.encode()).hexdigest()
        
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO vulnerabilities
            (code_hash, vulnerability_type, severity, description, fix_suggestion)
            VALUES (?, ?, ?, ?, ?)
        ''', (code_hash, vuln_type, severity, description, fix_suggestion))
        
        self.conn.commit()
    
    def get_vulnerabilities_by_type(self, vuln_type: str) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø«ØºØ±Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹"""
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT * FROM vulnerabilities 
            WHERE vulnerability_type = ?
            ORDER BY detected_at DESC
        ''', (vuln_type,))
        
        return [dict(row) for row in cursor.fetchall()]
    
    # ========== Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø£Ù…Ù†ÙŠ ==========
    
    def save_security_scan(self,
                           target: str,
                           scope_file: str,
                           findings_count: int,
                           risk_score: int,
                           report_path: str):
        """Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ù…Ø³Ø­ Ø£Ù…Ù†ÙŠ"""
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO security_scans
            (target, scope_file, findings_count, risk_score, report_path)
            VALUES (?, ?, ?, ?, ?)
        ''', (target, scope_file, findings_count, risk_score, report_path))
        
        self.conn.commit()
    
    def get_scan_history(self, target: str = None) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø³Ø­"""
        cursor = self.conn.cursor()
        
        if target:
            cursor.execute('''
                SELECT * FROM security_scans 
                WHERE target = ?
                ORDER BY scanned_at DESC
            ''', (target,))
        else:
            cursor.execute('SELECT * FROM security_scans ORDER BY scanned_at DESC')
        
        return [dict(row) for row in cursor.fetchall()]
    
    # ========== Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ==========
    
    def record_statistic(self, stat_type: str, stat_value: float):
        """ØªØ³Ø¬ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ©"""
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO statistics (stat_type, stat_value)
            VALUES (?, ?)
        ''', (stat_type, stat_value))
        self.conn.commit()
    
    def get_statistics(self, stat_type: str = None, days: int = 30) -> Dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
        cursor = self.conn.cursor()
        
        if stat_type:
            cursor.execute('''
                SELECT stat_type, AVG(stat_value) as avg_value, 
                       COUNT(*) as count, MAX(stat_date) as last_date
                FROM statistics
                WHERE stat_type = ? AND stat_date >= date('now', '-{} days')
                GROUP BY stat_type
            '''.format(days), (stat_type,))
        else:
            cursor.execute('''
                SELECT stat_type, AVG(stat_value) as avg_value,
                       COUNT(*) as count, MAX(stat_date) as last_date
                FROM statistics
                WHERE stat_date >= date('now', '-{} days')
                GROUP BY stat_type
            '''.format(days))
        
        return {row['stat_type']: dict(row) for row in cursor.fetchall()}
    
    # ========== Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± ==========
    
    def get_dashboard_stats(self) -> Dict:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…"""
        cursor = self.conn.cursor()
        
        # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙˆÙ„ÙŠØ¯Ø§Øª
        cursor.execute('SELECT COUNT(*) FROM generations')
        total_generations = cursor.fetchone()[0]
        
        # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¬ÙˆØ¯Ø©
        cursor.execute('SELECT AVG(quality_score) FROM generations')
        avg_quality = cursor.fetchone()[0] or 0
        
        # Ø§Ù„ØªÙˆÙ„ÙŠØ¯Ø§Øª Ø§Ù„ÙŠÙˆÙ…
        cursor.execute('''
            SELECT COUNT(*) FROM generations 
            WHERE date(created_at) = date('now')
        ''')
        today_generations = cursor.fetchone()[0]
        
        # Ø£ÙØ¶Ù„ Ø§Ù„Ù„ØºØ§Øª
        cursor.execute('''
            SELECT language, COUNT(*) as count 
            FROM generations 
            GROUP BY language 
            ORDER BY count DESC
        ''')
        top_languages = [dict(row) for row in cursor.fetchall()]
        
        # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø«ØºØ±Ø§Øª
        cursor.execute('SELECT COUNT(*) FROM vulnerabilities')
        total_vulns = cursor.fetchone()[0]
        
        # Ø§Ù„Ø«ØºØ±Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø®Ø·ÙˆØ±Ø©
        cursor.execute('''
            SELECT severity, COUNT(*) as count 
            FROM vulnerabilities 
            GROUP BY severity
        ''')
        vuln_by_severity = {row['severity']: row['count'] for row in cursor.fetchall()}
        
        return {
            "total_generations": total_generations,
            "average_quality": round(avg_quality, 2),
            "today_generations": today_generations,
            "top_languages": top_languages,
            "total_vulnerabilities": total_vulns,
            "vulnerabilities_by_severity": vuln_by_severity
        }
    
    def get_recent_activity(self, limit: int = 10) -> List[Dict]:
        """Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø£Ø®ÙŠØ±"""
        cursor = self.conn.cursor()
        
        cursor.execute('''
            SELECT 
                'generation' as type,
                prompt as description,
                quality_score,
                created_at
            FROM generations
            UNION ALL
            SELECT 
                'analysis' as type,
                code_snippet as description,
                quality_score,
                analyzed_at as created_at
            FROM analyses
            ORDER BY created_at DESC
            LIMIT ?
        ''', (limit,))
        
        return [dict(row) for row in cursor.fetchall()]
    
    # ========== Ø§Ù„ØªØ¹Ù„Ù… ==========
    
    def get_training_data(self, min_quality: float = 0.7, limit: int = 1000) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT prompt, generated_code, language, quality_score
            FROM generations
            WHERE quality_score >= ? AND user_rating IS NOT NULL
            ORDER BY user_rating DESC, quality_score DESC
            LIMIT ?
        ''', (min_quality, limit))
        
        return [dict(row) for row in cursor.fetchall()]
    
    def get_common_issues(self, limit: int = 10) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"""
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT 
                json_extract(value, '$.code') as issue_code,
                json_extract(value, '$.message') as message,
                COUNT(*) as frequency
            FROM analyses, json_each(analyses.issues)
            GROUP BY issue_code
            ORDER BY frequency DESC
            LIMIT ?
        ''', (limit,))
        
        return [dict(row) for row in cursor.fetchall()]
    
    # ========== Ø§Ù„ØµÙŠØ§Ù†Ø© ==========
    
    def cleanup_old_records(self, days: int = 90):
        """Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        cursor = self.conn.cursor()
        
        # Ø­Ø°Ù Ø§Ù„ØªÙˆÙ„ÙŠØ¯Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        cursor.execute('''
            DELETE FROM generations 
            WHERE created_at < date('now', '-{} days')
            AND user_rating IS NULL
        '''.format(days))
        
        generations_deleted = cursor.rowcount
        
        # Ø­Ø°Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        cursor.execute('''
            DELETE FROM analyses 
            WHERE analyzed_at < date('now', '-{} days')
        '''.format(days))
        
        analyses_deleted = cursor.rowcount
        
        self.conn.commit()
        
        print(f"ğŸ—‘ï¸  ØªÙ… Ø­Ø°Ù {generations_deleted} ØªÙˆÙ„ÙŠØ¯ Ùˆ {analyses_deleted} ØªØ­Ù„ÙŠÙ„")
    
    def vacuum(self):
        """Ø¶ØºØ· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        self.conn.execute('VACUUM')
        print("âœ… ØªÙ… Ø¶ØºØ· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    def close(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„"""
        self.conn.close()
        print("âœ… ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹
if __name__ == "__main__":
    with LearningDatabase() as db:
        # Ø­ÙØ¸ ØªÙˆÙ„ÙŠØ¯
        gen_id = db.save_generation(
            prompt="Calculate factorial",
            generated_code="def factorial(n): return 1 if n <= 1 else n * factorial(n-1)",
            language="python",
            quality_score=85.5,
            execution_time_ms=120.5
        )
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ„ÙŠØ¯: {gen_id}")
        
        # Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„
        analysis_id = db.save_analysis(
            code="def test(): pass",
            language="python",
            metrics={"lines": 10, "complexity": 2},
            issues=[],
            code_smells=[],
            quality_score=90.0
        )
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {analysis_id}")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        stats = db.get_dashboard_stats()
        print("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…:")
        for key, value in stats.items():
            print(f"   {key}: {value}")
