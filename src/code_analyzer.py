#!/usr/bin/env python3
"""
Ù…Ø­Ù„Ù„ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠ - Smart Code Analyzer
======================================
ÙŠØ­Ù„Ù„ Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯ ÙˆÙŠÙƒØªØ´Ù Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ ÙˆÙŠÙ‚ØªØ±Ø­ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª
"""

import ast
import re
import math
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from collections import Counter
import hashlib


@dataclass
class CodeMetrics:
    """Ù…Ù‚Ø§ÙŠÙŠØ³ Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯"""
    lines_of_code: int = 0
    logical_lines: int = 0
    comment_lines: int = 0
    blank_lines: int = 0
    complexity: int = 0
    max_nesting: int = 0
    function_count: int = 0
    class_count: int = 0
    average_function_length: float = 0.0
    duplicate_lines: int = 0
    test_coverage_estimate: float = 0.0


@dataclass
class CodeIssue:
    """Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ÙƒÙˆØ¯"""
    line: int
    severity: str  # ERROR, WARNING, INFO
    code: str
    message: str
    suggestion: str


class SmartCodeAnalyzer:
    """
    Ù…Ø­Ù„Ù„ ÙƒÙˆØ¯ Ø°ÙƒÙŠ ÙŠØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆÙŠÙƒØªØ´Ù Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
    """
    
    def __init__(self):
        self.metrics = CodeMetrics()
        self.issues: List[CodeIssue] = []
        self.keywords = [
            'def', 'class', 'if', 'else', 'elif', 'for', 'while',
            'try', 'except', 'finally', 'with', 'import', 'from',
            'return', 'yield', 'lambda', 'async', 'await'
        ]
        
    def analyze(self, code: str, filename: str = "<unknown>") -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„ÙƒÙˆØ¯"""
        self.issues = []
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØµÙŠØ§ØºØ©
        try:
            tree = ast.parse(code)
            is_valid = True
        except SyntaxError as e:
            self.issues.append(CodeIssue(
                line=e.lineno or 1,
                severity="ERROR",
                code="SYNTAX_ERROR",
                message=str(e),
                suggestion="ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙŠØ§ØºØ© Ø§Ù„ÙƒÙˆØ¯"
            ))
            tree = None
            is_valid = False
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        metrics = self._calculate_metrics(code, tree)
        
        # Ø§ÙƒØªØ´Ø§Ù Ø±ÙˆØ§Ø¦Ø­ Ø§Ù„ÙƒÙˆØ¯
        smells = self._detect_smells(code, tree, metrics)
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø³Ø±Ø§Ø±
        secrets = self._detect_secrets(code)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª
        imports = self._analyze_imports(tree) if tree else []
        
        # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬ÙˆØ¯Ø©
        quality_score = self._calculate_quality_score(metrics, smells, secrets)
        
        return {
            "filename": filename,
            "is_valid": is_valid,
            "metrics": metrics.__dict__,
            "issues": [self._issue_to_dict(i) for i in self.issues],
            "code_smells": smells,
            "secrets_detected": secrets,
            "imports": imports,
            "quality_score": quality_score,
            "language": self._detect_language(code),
            "hash": hashlib.md5(code.encode()).hexdigest()[:12]
        }
    
    def _calculate_metrics(self, code: str, tree: Optional[ast.AST]) -> CodeMetrics:
        """Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙƒÙˆØ¯"""
        lines = code.split('\n')
        
        metrics = CodeMetrics()
        metrics.lines_of_code = len(lines)
        metrics.blank_lines = sum(1 for line in lines if not line.strip())
        metrics.comment_lines = sum(1 for line in lines if line.strip().startswith('#'))
        
        # Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ© (ØºÙŠØ± Ø§Ù„ÙØ§Ø±ØºØ© ÙˆØºÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª)
        metrics.logical_lines = sum(1 for line in lines 
                                    if line.strip() and not line.strip().startswith('#'))
        
        if tree:
            # ØªØ¹Ù‚ÙŠØ¯ Cyclomatic
            metrics.complexity = self._calculate_complexity(tree)
            
            # Ø£Ù‚ØµÙ‰ ØªØ¯Ø§Ø®Ù„
            metrics.max_nesting = self._calculate_max_nesting(tree)
            
            # Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ§Ù„ ÙˆØ§Ù„ÙØ¦Ø§Øª
            metrics.function_count = len([n for n in ast.walk(tree) 
                                          if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef))])
            metrics.class_count = len([n for n in ast.walk(tree) 
                                       if isinstance(n, ast.ClassDef)])
            
            # Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¯Ø§Ù„Ø©
            func_lengths = []
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    func_length = node.end_lineno - node.lineno if node.end_lineno else 10
                    func_lengths.append(func_length)
            
            if func_lengths:
                metrics.average_function_length = sum(func_lengths) / len(func_lengths)
        
        return metrics
    
    def _calculate_complexity(self, tree: ast.AST) -> int:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¯ÙˆØ±Ø§Ù†ÙŠ (Cyclomatic Complexity)"""
        complexity = 1  # Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, 
                                ast.ExceptHandler, ast.With, ast.Assert)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
        
        return complexity
    
    def _calculate_max_nesting(self, tree: ast.AST) -> int:
        """Ø­Ø³Ø§Ø¨ Ø£Ù‚ØµÙ‰ Ù…Ø³ØªÙˆÙ‰ ØªØ¯Ø§Ø®Ù„"""
        max_nesting = 0
        
        def visit_node(node, current_depth=0):
            nonlocal max_nesting
            max_nesting = max(max_nesting, current_depth)
            
            for child in ast.iter_child_nodes(node):
                if isinstance(child, (ast.If, ast.For, ast.While, 
                                    ast.FunctionDef, ast.ClassDef, ast.With)):
                    visit_node(child, current_depth + 1)
                else:
                    visit_node(child, current_depth)
        
        visit_node(tree)
        return max_nesting
    
    def _detect_smells(self, code: str, tree: Optional[ast.AST], 
                       metrics: CodeMetrics) -> List[Dict[str, Any]]:
        """Ø§ÙƒØªØ´Ø§Ù Ø±ÙˆØ§Ø¦Ø­ Ø§Ù„ÙƒÙˆØ¯"""
        smells = []
        
        # Ø¯Ø§Ù„Ø© Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹
        if metrics.average_function_length > 30:
            smells.append({
                "type": "LONG_FUNCTION",
                "severity": "WARNING",
                "message": f"Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¯Ø§Ù„Ø© {metrics.average_function_length:.1f} Ø³Ø·Ø±",
                "suggestion": "Ù‚Ø³Ù‘Ù… Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¥Ù„Ù‰ Ø¯ÙˆØ§Ù„ Ø£ØµØºØ±"
            })
        
        # ØªØ¹Ù‚ÙŠØ¯ Ø¹Ø§Ù„Ù
        if metrics.complexity > 10:
            smells.append({
                "type": "HIGH_COMPLEXITY",
                "severity": "WARNING", 
                "message": f"ØªØ¹Ù‚ÙŠØ¯ Ø¯ÙˆØ±Ø§Ù†ÙŠ Ø¹Ø§Ù„Ù: {metrics.complexity}",
                "suggestion": "Ø¨Ø³Ù‘Ø· Ø§Ù„Ù…Ù†Ø·Ù‚ Ø£Ùˆ Ø§Ø³ØªØ®Ø±Ø¬ Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©"
            })
        
        # ØªØ¯Ø§Ø®Ù„ Ø¹Ù…ÙŠÙ‚
        if metrics.max_nesting > 4:
            smells.append({
                "type": "DEEP_NESTING",
                "severity": "WARNING",
                "message": f"ØªØ¯Ø§Ø®Ù„ Ø¹Ù…ÙŠÙ‚: {metrics.max_nesting} Ù…Ø³ØªÙˆÙŠØ§Øª",
                "suggestion": "Ø§Ø³ØªØ®Ø¯Ù… return Ù…Ø¨ÙƒØ± Ø£Ùˆ Ø§Ø³ØªØ®Ø±Ø¬ Ø¯ÙˆØ§Ù„"
            })
        
        # ÙƒÙˆØ¯ Ø¨Ø¯ÙˆÙ† ØªØ¹Ù„ÙŠÙ‚Ø§Øª
        comment_ratio = metrics.comment_lines / max(metrics.lines_of_code, 1)
        if comment_ratio < 0.05 and metrics.lines_of_code > 20:
            smells.append({
                "type": "NO_COMMENTS",
                "severity": "INFO",
                "message": "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§Ù‹",
                "suggestion": "Ø£Ø¶Ù docstrings ÙˆØªØ¹Ù„ÙŠÙ‚Ø§Øª ØªÙˆØ¶ÙŠØ­ÙŠØ©"
            })
        
        # ÙƒÙˆØ¯ Ù…ÙƒØ±Ø±
        duplicates = self._detect_duplicates(code)
        if duplicates:
            smells.append({
                "type": "DUPLICATE_CODE",
                "severity": "WARNING",
                "message": f"{len(duplicates)} ÙƒØªÙ„ ÙƒÙˆØ¯ Ù…ÙƒØ±Ø±Ø©",
                "suggestion": "Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ø´ØªØ±Ùƒ Ø¥Ù„Ù‰ Ø¯Ø§Ù„Ø©"
            })
        
        # Ù…ØªØºÙŠØ±Ø§Øª ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø©
        if tree:
            unused = self._detect_unused_variables(tree)
            if unused:
                smells.append({
                    "type": "UNUSED_VARIABLES",
                    "severity": "INFO",
                    "message": f"Ù…ØªØºÙŠØ±Ø§Øª ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø©: {', '.join(unused[:3])}",
                    "suggestion": "Ø§Ø­Ø°Ù Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©"
                })
        
        return smells
    
    def _detect_duplicates(self, code: str, min_lines: int = 5) -> List[Dict]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙƒØ±Ø±"""
        lines = [line.strip() for line in code.split('\n') if line.strip()]
        duplicates = []
        seen = {}
        
        for i in range(len(lines) - min_lines + 1):
            block = '\n'.join(lines[i:i + min_lines])
            block_hash = hashlib.md5(block.encode()).hexdigest()
            
            if block_hash in seen:
                duplicates.append({
                    "first_at": seen[block_hash],
                    "duplicate_at": i,
                    "block": block[:100]
                })
            else:
                seen[block_hash] = i
        
        return duplicates
    
    def _detect_unused_variables(self, tree: ast.AST) -> List[str]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©"""
        assigned = set()
        used = set()
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Name):
                if isinstance(node.ctx, ast.Store):
                    assigned.add(node.id)
                elif isinstance(node.ctx, ast.Load):
                    used.add(node.id)
        
        return list(assigned - used - {'_', 'self', 'cls'})
    
    def _detect_secrets(self, code: str) -> List[Dict]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø³Ø±Ø§Ø± ÙˆØ§Ù„Ù…ÙØ§ØªÙŠØ­"""
        secrets = []
        
        patterns = {
            'API_KEY': r'api[_-]?key\s*[=:]\s*["\'][a-zA-Z0-9]{16,}["\']',
            'PASSWORD': r'password\s*[=:]\s*["\'][^"\']+["\']',
            'SECRET': r'secret\s*[=:]\s*["\'][a-zA-Z0-9]{8,}["\']',
            'TOKEN': r'token\s*[=:]\s*["\'][a-zA-Z0-9]{10,}["\']',
            'PRIVATE_KEY': r'-----BEGIN (RSA |EC |DSA |OPENSSH )?PRIVATE KEY-----'
        }
        
        for secret_type, pattern in patterns.items():
            matches = re.finditer(pattern, code, re.IGNORECASE)
            for match in matches:
                secrets.append({
                    "type": secret_type,
                    "line": code[:match.start()].count('\n') + 1,
                    "snippet": match.group()[:50] + "..."
                })
        
        return secrets
    
    def _analyze_imports(self, tree: ast.AST) -> List[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª"""
        imports = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append({
                        "type": "import",
                        "module": alias.name,
                        "alias": alias.asname
                    })
            elif isinstance(node, ast.ImportFrom):
                imports.append({
                    "type": "from_import",
                    "module": node.module,
                    "names": [a.name for a in node.names]
                })
        
        return imports
    
    def _calculate_quality_score(self, metrics: CodeMetrics, 
                                  smells: List[Dict], 
                                  secrets: List[Dict]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯ (0-100)"""
        score = 100.0
        
        # Ø®ØµÙ… Ù„Ù„ØªØ¹Ù‚ÙŠØ¯
        if metrics.complexity > 10:
            score -= min(20, (metrics.complexity - 10) * 2)
        
        # Ø®ØµÙ… Ù„Ù„ØªØ¯Ø§Ø®Ù„
        if metrics.max_nesting > 3:
            score -= min(15, (metrics.max_nesting - 3) * 5)
        
        # Ø®ØµÙ… Ù„Ø·ÙˆÙ„ Ø§Ù„Ø¯ÙˆØ§Ù„
        if metrics.average_function_length > 20:
            score -= min(15, (metrics.average_function_length - 20))
        
        # Ø®ØµÙ… Ù„Ù„Ø±ÙˆØ§Ø¦Ø­
        for smell in smells:
            if smell["severity"] == "ERROR":
                score -= 15
            elif smell["severity"] == "WARNING":
                score -= 8
            else:
                score -= 3
        
        # Ø®ØµÙ… ÙƒØ¨ÙŠØ± Ù„Ù„Ø£Ø³Ø±Ø§Ø±
        score -= len(secrets) * 20
        
        return max(0, min(100, score))
    
    def _detect_language(self, code: str) -> str:
        """Ø§ÙƒØªØ´Ø§Ù Ù„ØºØ© Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©"""
        indicators = {
            'python': [r'def\s+\w+\s*\(', r'import\s+\w+', r'print\s*\(', r'\s*#'],
            'javascript': [r'function\s+\w+', r'const\s+\w+\s*=', r'console\.log'],
            'java': [r'public\s+class', r'System\.out\.println', r'private\s+\w+'],
        }
        
        scores = {}
        for lang, patterns in indicators.items():
            score = sum(1 for p in patterns if re.search(p, code))
            scores[lang] = score
        
        return max(scores, key=scores.get) if max(scores.values()) > 0 else 'unknown'
    
    def _issue_to_dict(self, issue: CodeIssue) -> Dict:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³"""
        return {
            "line": issue.line,
            "severity": issue.severity,
            "code": issue.code,
            "message": issue.message,
            "suggestion": issue.suggestion
        }
    
    def extract_features(self, code: str) -> Dict[str, float]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
        analysis = self.analyze(code)
        metrics = analysis['metrics']
        
        return {
            'lines_of_code': float(metrics['lines_of_code']),
            'logical_lines': float(metrics['logical_lines']),
            'complexity': float(metrics['complexity']),
            'max_nesting': float(metrics['max_nesting']),
            'function_count': float(metrics['function_count']),
            'class_count': float(metrics['class_count']),
            'avg_function_length': float(metrics['average_function_length']),
            'comment_ratio': metrics['comment_lines'] / max(metrics['lines_of_code'], 1),
            'quality_score': float(analysis['quality_score']),
            'smell_count': float(len(analysis['code_smells'])),
            'has_secrets': float(len(analysis['secrets_detected'])),
        }


class CodeQualityAnalyzer:
    """
    Ù…Ø­Ù„Ù„ Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
    """
    
    def __init__(self):
        self.smart_analyzer = SmartCodeAnalyzer()
    
    def analyze(self, code: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø¬ÙˆØ¯Ø©"""
        basic = self.smart_analyzer.analyze(code)
        
        # ØªØ­Ù„ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ
        maintainability = self._calculate_maintainability(basic['metrics'])
        reliability = self._calculate_reliability(basic)
        
        return {
            **basic,
            "maintainability_index": maintainability,
            "reliability_score": reliability,
            "overall_score": (basic['quality_score'] + maintainability + reliability) / 3,
            "issues": basic['issues'],
            "recommendations": self._generate_recommendations(basic)
        }
    
    def _calculate_maintainability(self, metrics: Dict) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„ØµÙŠØ§Ù†Ø©"""
        # ØµÙŠØºØ© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„Ù…Ø¤Ø´Ø±
        halstead_volume = metrics['logical_lines'] * math.log2(max(metrics['logical_lines'], 2))
        cyclomatic = metrics['complexity']
        lines_of_code = metrics['lines_of_code']
        
        maintainability = 171 - 5.2 * math.log(halstead_volume + 1) \
                         - 0.23 * cyclomatic - 16.2 * math.log(lines_of_code + 1)
        
        return max(0, min(100, maintainability))
    
    def _calculate_reliability(self, analysis: Dict) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©"""
        score = 100.0
        
        # Ø®ØµÙ… Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
        errors = sum(1 for i in analysis['issues'] if i['severity'] == 'ERROR')
        score -= errors * 20
        
        # Ø®ØµÙ… Ù„Ù„ØªØ­Ø°ÙŠØ±Ø§Øª
        warnings = sum(1 for i in analysis['issues'] if i['severity'] == 'WARNING')
        score -= warnings * 5
        
        # Ø®ØµÙ… Ù„Ù„Ø«ØºØ±Ø§Øª
        score -= len(analysis.get('secrets_detected', [])) * 25
        
        return max(0, score)
    
    def _generate_recommendations(self, analysis: Dict) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª"""
        recommendations = []
        
        if analysis['metrics']['complexity'] > 10:
            recommendations.append("Ù‚Ù„Ù„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø¨Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯ÙˆØ§Ù„")
        
        if analysis['metrics']['average_function_length'] > 25:
            recommendations.append("Ù‚Ø³Ù‘Ù… Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©")
        
        if analysis['metrics']['comment_lines'] < 5:
            recommendations.append("Ø£Ø¶Ù Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª")
        
        if analysis.get('secrets_detected'):
            recommendations.append("Ø£Ø²Ù„ Ø§Ù„Ø£Ø³Ø±Ø§Ø± Ù…Ù† Ø§Ù„ÙƒÙˆØ¯ - Ø§Ø³ØªØ®Ø¯Ù… Ù…ØªØºÙŠØ±Ø§Øª Ø¨ÙŠØ¦Ø©")
        
        return recommendations


# Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹
if __name__ == "__main__":
    test_code = '''
def calculate_factorial(n):
    """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ø§Ù…Ù„ÙŠØ©"""
    if n == 0:
        return 1
    else:
        return n * calculate_factorial(n-1)

class Calculator:
    def add(self, a, b):
        return a + b
    
    def complex_method(self, x, y, z):
        if x > 0:
            if y > 0:
                if z > 0:
                    return x + y + z
        return 0

API_KEY = "sk-1234567890abcdef"
'''
    
    analyzer = SmartCodeAnalyzer()
    result = analyzer.analyze(test_code, "test.py")
    
    print("=" * 60)
    print("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    print("=" * 60)
    print(f"\nâœ… ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ÙƒÙˆØ¯: {result['is_valid']}")
    print(f"ğŸ“ˆ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬ÙˆØ¯Ø©: {result['quality_score']:.1f}/100")
    print(f"\nğŸ“ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³:")
    for key, value in result['metrics'].items():
        print(f"   {key}: {value}")
    
    print(f"\nâš ï¸  Ø±ÙˆØ§Ø¦Ø­ Ø§Ù„ÙƒÙˆØ¯ ({len(result['code_smells'])}):")
    for smell in result['code_smells']:
        print(f"   [{smell['severity']}] {smell['type']}: {smell['message']}")
    
    if result['secrets_detected']:
        print(f"\nğŸ” Ø£Ø³Ø±Ø§Ø± Ù…ÙƒØªØ´ÙØ©:")
        for secret in result['secrets_detected']:
            print(f"   {secret['type']} ÙÙŠ Ø§Ù„Ø³Ø·Ø± {secret['line']}")
